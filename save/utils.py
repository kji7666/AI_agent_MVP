from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import src.config as config

def get_llm(temperature=0.7):
    """
    å›å‚³ LangChain çš„ ChatOllama ç‰©ä»¶ï¼Œå·²è¨­å®šå¥½å­¸æ ¡çš„ API Headerã€‚
    """
    return ChatOllama(
        base_url=config.API_HOST,
        model=config.MODEL_NAME,
        temperature=temperature,
        # é—œéµï¼šå°‡ Authorization header æ³¨å…¥è«‹æ±‚ä¸­
        headers={'Authorization': f'Bearer {config.LLM_API_KEY}'}
    )

def get_embedding_model():
    """
    å›å‚³æœ¬åœ°é‹è¡Œçš„ Embedding æ¨¡å‹ (ä¸æ¶ˆè€—å­¸æ ¡ API Quota)ã€‚
    ä½¿ç”¨ 'all-MiniLM-L6-v2'ï¼Œé€™æ˜¯ä¸€å€‹é€Ÿåº¦å¿«ä¸”æ•ˆæœå¥½çš„æ¨™æº–æ¨¡å‹ã€‚
    """
    print("ğŸ”„ Loading local embedding model (this may take a moment first time)...")
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

def get_vector_store():
    """
    åˆå§‹åŒ–æˆ–é€£æ¥ ChromaDBã€‚
    """
    embedding_function = get_embedding_model()
    
    vector_store = Chroma(
        collection_name="agent_memories",
        embedding_function=embedding_function,
        persist_directory=config.DB_PERSIST_DIRECTORY
    )
    return vector_store