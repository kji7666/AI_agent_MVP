from typing import List
from langchain_core.prompts import ChatPromptTemplate
from src.llm_factory import get_llm
from src.memory.retriever import GenerativeRetriever

class Reflector:
    def __init__(self, retriever: GenerativeRetriever):
        self.retriever = retriever
        self.llm = get_llm(temperature=0.5) # åæ€éœ€è¦ä¸€é»å‰µæ„

    def run(self, agent_name: str, last_k: int = 20):
        """
        åŸ·è¡Œåæ€ç¨‹åºï¼š
        1. æ’ˆå–æœ€è¿‘ k æ¢å°šæœªåæ€éçš„è¨˜æ†¶
        2. è«‹ LLM æ­¸ç´
        3. å°‡æ­¸ç´çµæœ (Insight) å¯«å›è¨˜æ†¶åº«
        """
        print(f"ğŸ¤” {agent_name} is reflecting on recent events...")
        
        # 1. ç‚ºäº†ç°¡åŒ– MVPï¼Œæˆ‘å€‘ç›´æ¥æ’ˆå–æœ€è¿‘çš„è¨˜æ†¶ (ä¸è«–æ˜¯å¦åæ€é)
        # åœ¨å®Œæ•´ç‰ˆä¸­ï¼Œæˆ‘å€‘æ‡‰è©²è¨˜éŒ„ä¸€å€‹ 'last_reflected_time' æŒ‡æ¨™
        recent_memories = self.retriever.retrieve(
            query=f"What happened to {agent_name} recently?",
            k=last_k,
            fetch_k=last_k * 2
        )
        
        if not recent_memories:
            print("   No memories to reflect on.")
            return

        # å°‡è¨˜æ†¶è½‰ç‚ºæ–‡å­—æ¸…å–®
        observations = [m.page_content for m in recent_memories]
        observations_str = "\n".join([f"- {o}" for o in observations])

        # 2. å‘¼å« LLM é€²è¡Œæ­¸ç´
        # è«–æ–‡æŠ€å·§ï¼šAsk "What high-level insights can you infer?"
        prompt = ChatPromptTemplate.from_template("""
        {observations}
        
        Given only the information above, what are 3 most salient high-level insights 
        we can infer about {agent_name}?
        
        Respond with 3 distinct sentences, one per line. Do not include numbering.
        """)
        
        chain = prompt | self.llm
        
        try:
            response = chain.invoke({
                "observations": observations_str, 
                "agent_name": agent_name
            })
            insights = response.content.strip().split('\n')
            
            # 3. å°‡ Insight å­˜å›è¨˜æ†¶åº«
            for insight in insights:
                insight = insight.strip()
                # å»é™¤å¯èƒ½çš„ç·¨è™Ÿ (1. 2. - ç­‰)
                if insight and len(insight) > 10: 
                    print(f"   ğŸ’¡ Insight generated: {insight}")
                    # å¯«å…¥æ™‚æ¨™è¨˜ type='reflection'
                    self.retriever.add_memory(
                        content=insight,
                        type="reflection"
                    )
                    
        except Exception as e:
            print(f"âŒ Reflection failed: {e}")